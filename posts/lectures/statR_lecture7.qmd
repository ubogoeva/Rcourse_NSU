---
title: "Язык программирования R для анализа данных: лекция 7"
subtitle: 'Введение в статистику вывода: продолжение'
author: "Elena U"
#date: "Created on 01 April, 2023"
execute:
  echo: true
  output: true
format: 
  revealjs:
    slide-number: c/t
    show-slide-number: all
    # mainfont: Arial
    # fontsize: 14px
    theme: [default, custom.scss]
    chalkboard: 
      buttons: true
    # theme: [serif]
    # mouse-wheel: true
    auto-play-media: true
    width: 1280
    height: 720
    fig-dpi: 300
    # logo: figures/icg.png
revealjs-plugins:
  - pointer
editor: visual
draft: true
---

## План лекции

-   Параметры и статистики.

-   Виды распределений: функции плотности вероятности (probability density/mass functions), кумулятивные функции распределения.

-   Стандартное нормальное распределение, центральная предельная теорема.

-   Стандартная ошибка и доверительный интервал.

-   Алгоритм статистического вывода на примере Z-теста.

-   Тест Стьюдента.

## Параметры и статистики

Population - генеральная совокупность.

Sample - выборка.

|                          |                                                                          |
|---------------------|:--------------------------------------------------|
| [P]{.underline}opulation | [P]{.underline}arameter (обозначают греческими буквами: $\mu$, $\sigma$. |
| [S]{.underline}ample     | [S]{.underline}tatistics (обозначают например $\overline{x}$, $sd$)      |

Например, у стандартного нормального распределения среднее $\mu$ 0 и стандартное отклонение $\sigma$ 1, и эти значения являются *параметрами*, поскольку описывают теоретическое распределение (генеральную совокупность).

Например, в датасете `iris` среднее `Sepal.Length` равно 5.84, а стандартное отклонение 0.828, и эти значения являются *статистиками* (описывают выборку).

```{r}
mean(iris$Sepal.Length)
sd(iris$Sepal.Length)
```

## Полезные функции для генерации различных распределений

Можно посмотреть в cheatsheet по base R.

![](https://pozdniakov.github.io/tidy_stats/images/rdists.PNG){width="613"}

Наиболее полезные функции: density (`d*()`), cumulative distribution (`p*()`) и random (`r*()`).

::: {.callout-tip appearance="simple"}
Со списком всех доступных в base R распределений можно ознакомиться, вызвав

```{r}
#| eval: false
?Distributions
```
:::

## Стандартное нормальное распределение

Стандартное нормальное распределение имеет среднее 0 и стандартное отклонение 1. Важно отметить, что здесь мы говорим о *параметрах* генеральной совокупности, а не о статистиках.

![](https://pozdniakov.github.io/tidy_stats/images/normalstandard.jpg)

## Функция плотности вероятности нормального распределения: `dnorm()`

::: incremental
-   Density function

    ```{r}
    dnorm(0)
    # что получится, если запустить dnorm(1)?
    ```

-   

    ```{r}
    dnorm(1)
    # а если запустить dnorm(-1)?
    ```

-   

    ```{r}
    dnorm(-1)
    ```
:::

## Функция плотности вероятности стандартного нормального распределения {style="font-size: 80%"}

::: {.callout-note appearance="simple"}
Забавный момент: для дискретных распределений называется *probability mass function*, для непрерывных - *probability density function*, на русский язык переводится одинаково: функция плотности вероятности.
:::

Давайте отрисуем функцию плотности вероятности стандартного нормального распределения с помощью `dnorm()`.

```{r}
vec <- seq(-3, 3, 0.01)
plot(vec, dnorm(vec))
```

## Функция плотности вероятности шкалы IQ

```{r}
iq <- seq(50, 150, 0.1)
plot(iq, dnorm(iq, mean = 100, sd = 15))
```

Шкала IQ отнормирована таким образом, чтобы среднее генеральной совокупности было равно 100, а стандартное отклонение 15.

## `pnorm()` - кумулятивная функция распределения (cumulative density function)

На примере стандартного нормального распределения.

```{r}
plot(vec, pnorm(vec))
```

`pnorm()` отражает вероятность получить такое же или меньшее значение в нормальном распределении (в данном случае в стандартном).

## `pnorm()` - кумулятивная функция распределения (cumulative density function)

На примере шкалы IQ.

::: incremental
-   Чему будет равно значение `pnorm(100)` для этой шкалы? То есть какая вероятность получить значение меньше чем 100?

-   

    ```{r}
    pnorm(100, mean = 100, sd = 15) # не забываем прописывать mean, sd
    ```

-   Среднее равно 100, следовательно -\> пояснение на графике

-   Чему равно значение `pnorm(130)` для шкалы IQ?

-   

    ```{r}
    pnorm(130, mean = 100, sd = 15)
    ```
:::

## `rnorm()` - функция для генерации случайных значений из заданного распределения

```{r}
set.seed(42) # для воспроизводимости 'рандома'
rnorm(30)
rnorm(30)
```

Сид нужно фиксировать каждый раз перед запуском чего-то зависящего от случайности.

## Вычисление стандартного отклонения

```{r}
set.seed(50) # для фиксации рандома
samp <- rnorm(100, mean = 100, sd = 15)
sqrt(sum((samp - mean(samp)) ^ 2) / (length(samp))) # совпадает ли с результатом функции sd?
sd(samp)
```

Почему не совпадает?

$$
sd = \sqrt{var} =\sqrt{\frac{\sum_{i=1}^n(x_i - \overline{x})^2}{n}}
$$

## Формула стандартного отклонения

Во встроенной функции `sd()`, которая опирается на функцию `var()`, в формуле n-1 в знаменателе.

$$
sd = \sqrt{var} =\sqrt{\frac{\sum_{i=1}^n(x_i - \overline{x})^2}{n - 1}}
$$

Такая оценка стандартного отклонения называется несмещенной (unbiased) оценкой.

Почему n-1 в знаменателе -\> объяснение на графике.

## Значение центральной предельной теоремы

Мысленный эксперимент: многократно извлекаем выборки из генеральной совокупности, считаем средние по выборкам.

```{r}
samp_means <- replicate(1000, mean(rnorm(100, mean = 100, sd = 15)))
hist(samp_means, breaks = 30)

```

Распределение средних, извлеченных из нормального распределения, примерно нормальное. Это неудивительно, попробуем теперь в качестве генеральной совокупности использовать лог-нормальное распределение.

## Лог-нормальное распределение

```{r}
hist(rlnorm(100), breaks = 30)

```

## Распределение средних лог-нормального распределения {style="font-size: 90%"}

```{r}
samp_means_log <- replicate(1000, mean(rlnorm(100)))
hist(samp_means_log, breaks = 30)
```

А вот распределение средних из изначально не-нормального распределение тоже похоже на нормальное распределение! Это получается благодаря центральной предельной теореме.

[Шайни апп для центральной предельной теоремы](https://gallery.shinyapps.io/CLT_mean/)

## Выведение стандартной ошибки

::: incremental
-   Среднее выборочного распределения средних близко к популяционному среднему:

    ```{r}
    mean(samp_means)
    ```

-   Чему же равно стандартное отклонение средних?

-   

    ```{r}
    sd(samp_means)
    ```

-   Оно примерно равно стандартному отклонению генеральной совокупности деленное на 10 - корень из размера выборки (100).
:::

## Формула стандартной ошибки

$$
\sigma_{\overline{x}}= \frac{\sigma} {\sqrt{n}}
$$

Стандартное отклонение выборочного распределения средних называется еще стандартной ошибкой или standard error of the mean (s.e.m.). Нередко стандартную ошибку используют на графиках в качестве error bars.

```{r}
sem <- 15/sqrt(length(samp))
sem
```

Поскольку обычно мы не знаем истинное стандартное отклонение генеральной совокупности ($\sigma$), то используем стандартное отклонение выборки $sd$.

$$
s_{\overline{x}}= \frac{sd} {\sqrt{n}}
$$

## Доверительный интервал

Мы хотим поймать симметрично 95% от площади под кривой. Для этого нам нужно отбросить по 2.5% с обоих сторон. Эти 2.5% соответствуют примерно двум стандартным отклонениям от среднего. Если быть точнее, то 1.96. Если быть еще точнее:

```{r}
qnorm(0.975)
zcr <- qnorm(1 - (1 - 0.95)/2)
zcr
```

```{r}
sem <- 15/sqrt(length(samp))
mean(samp) - sem*zcr #нижняя граница
mean(samp) + sem*zcr #верхняя граница
```

## Доверительный интервал

Попробуем отрисовать доверительные интервалы:

```{r}
library(tidyverse)
sample_size <- 100
set.seed(40)
ci_simulations <- tibble(
  m = replicate(sample_size, mean(rnorm(sample_size, mean = 100, sd = 15))),
  se = 15/sqrt(sample_size),
  lower = m - se*zcr,
  higher = m + se*zcr,
  parameter_inside = lower<100 & higher>100
)
many_ci_gg <- ggplot(data = ci_simulations, aes(x = 1:sample_size,y = m)) +
  geom_pointrange(aes(ymin = lower,ymax = higher,colour = parameter_inside))+
  geom_hline(yintercept = 100)+
  coord_flip() +
  theme_minimal()

```

## Визуализация доверительных интервалов

```{r}
many_ci_gg
```

Еще одна [Визуализация доверительных интервалов](http://rpsychologist.com/d3/CI/)

## Алгоритм статистического вывода

1.  Формулировка нулевой и альтернативной гипотезы.

2.  Вычисление тестовых статистик.

3.  Подсчет p-value как площади под кривой выборочного распределения тестовых статистик.

4.  Вывод: отклоняем или не отклоняем нулевую гипотезу.

# Разберем на примере z-теста

## Формулировка нулевой и альтернативной гипотезы:

-   $H_0$: $m = \mu$ нулевая гипотеза, например, что среднее выборки статистически не отличается от среднего генеральной совокупности

-   $H_1: m \neq \mu$ альтернативная гипотеза, о том что средние не равны

## Вычисление тестовой статистики

Формула z-скора

$$
z = \frac{m - \mu_{H_0}}{\sigma/\sqrt{N}},
$$

где m - среднее выборки, $\mu_{H_0}$ - среднее генеральной совокупности, $\sigma$ - стандартное отклонение генеральной совокупности, $N$ - размер выборки.

```{r}
set.seed(42) # для фиксации рандома
samp <- rnorm(100, mean = 100, sd = 15)
m <- mean(samp)
m
sem <- 15/sqrt(length(samp))
z <- (m - 100)/sem
z
```

## Вычисление p-value

```{r}
pnorm(z)
```

`pnorm()` считает от минус бесконечности до заданного числа, а нам нужно наоборот --- от заданного числа до плюс бесконечности, потому что $z$ больше нуля. Этого можно добиться вычитанием из 1.

Поскольку мы не знаем в какую сторону у нас ожидается эффект, то нужно еще учесть симметричную площадь под кривой.

```{r}
1 - pnorm(z)
p_value <- (1 - pnorm(z))*2
p_value
```

Много это или мало? Какой делаем вывод?

## Вывод

p-value \> 0.05, порогового значения $\alpha$, следовательно мы НЕ отклоняем нулевую гипотезу.

## Тест Стьюдента или t-test

На практике z-тест не используется, потому что предполагает, что мы знаем стандартное отклонение в генеральной совокупности. Обычно это не так, поэтому мы оцениваем стандартное отклонение в генеральной совокупности на основе стандартного отклонения по выборке.

Это приводит к тому, что тестовая статистика уже не распределена нормально, а распределена согласно t-распределению. Статистика называется t-статистикой.

$$
t = \frac{\overline{x} - \mu} {s_x / \sqrt{N}}
$$

## Распределение Стьюдента или t-распределение

Есть параметр степеней свободы: размер выборки -1

![](https://pozdniakov.github.io/tidy_stats/320-ttest_files/figure-html/unnamed-chunk-1-1.png)

t-распределение имеет более тяжелые хвосты.

При размере выборке стремящемуся к бесконечности, t-распределение стремится к нормальному.

## Проведение теста Стьюдента

Формулировка нулевой и альтернативной гипотезы не изменилась.

Теперь в качестве тестовой статистики вычисляем t-статистику по формуле:

$$
t = \frac{\overline{x} - \mu} {s_x / \sqrt{N}}
$$

```{r}
m <- mean(samp)
sem <- sd(samp)/sqrt(length(samp)) # разница на этом шаге
t <- (m - 100)/sem
t
(m - 100) / (15/sqrt(100)) # это z-score, значения близки

```

## Вычисление p-value в тесте Стьюдента

Теперь вычисляем p-value как площадь под кривой распределения t-статистики. Для этого используем уже не `pnorm()`, а `pt()`.

```{r}
pt(t, df = length(samp) - 1) # здесь различие от z-теста
1 - pt(t, df = length(samp) - 1) # односторонний
(1 - pt(t, df = length(samp) - 1))*2 # двусторонний
t.test(samp, mu = 100) # проверка
```

------------------------------------------------------------------------

Картинка Ивана Позднякова с описанием этапов статистического вывода

![](images/image-1909717986.png)

## 

Тест Стьюдента для сравнения двух выборок

```{r}
#| echo: false
library(tidyverse)
wc3_units <- read_tsv('https://raw.githubusercontent.com/ubogoeva/tidyverse_tutorial/master/data/wc3_heroes.txt',
                      col_names = TRUE, 
                      na = '-', 
                      name_repair = 'minimal') %>% 
  janitor::clean_names() # для правильных названий колонок
```

```{r}
wc3_units_armor <- wc3_units %>% 
  filter(armor_type == 'Heavy' | armor_type == 'Light')
t.test(wc3_units_armor$hp ~ wc3_units_armor$armor_type)
```

------------------------------------------------------------------------

Можно в функцию `t.test()` подавать два вектора:

```{r}
t.test(seq(1, 10, 0.1), seq(5, 12, 0.2))
```

## Тест Стьюдента и тест Велча {style="font-size:90%"}

На самом деле по умолчанию в R запускается тест Велча, поскольку предполагается, что дисперсии двух выборок не равны

Формула теста Стьюдента:

$$
t = \frac{\overline{X_1}-\overline{X_2}}{s_x\sqrt{\frac{1}{n_1} + \frac{1}{n_2}}},
s_x = \sqrt{\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}
$$

Чтобы запустить именно тест Стьюдента, можно использовать аргумент `var.equal = TRUE`

```{r}
t.test(wc3_units_armor$hp ~ wc3_units_armor$armor_type, 
       var.equal = TRUE)
```

Однако это делать не рекомендуется, поскольку при равных дисперсиях тест Стьюдента не будет сильно отличаться от теста Велча, а при разных тест Велча точнее.

------------------------------------------------------------------------

Формула теста Велча:

$$
t = \frac{\overline{X}_1 - \overline{X}_2}{\sqrt{\frac{s_1^2}{n_1} + \frac{s_2^2}{n_2}}}
$$

Количество степеней свободы:

$$
df = \frac{(s_1^2/n_1 + s_2^2 / n_2)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}
$$

По умолчанию рекомендуется использовать тест Велча.
