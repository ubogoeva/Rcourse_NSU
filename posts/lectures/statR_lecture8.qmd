---
title: "Язык программирования R для анализа данных: лекция 8"
subtitle: 'Тест Стьюдента, Манна-Уитни'
author: "Elena U"
#date: "Created on 01 April, 2023"
execute:
  echo: true
  output: true
format: 
  revealjs:
    slide-number: c/t
    show-slide-number: all
    # mainfont: Arial
    # fontsize: 14px
    theme: [default, custom.scss]
    chalkboard: 
      buttons: true
    # theme: [serif]
    # mouse-wheel: true
    auto-play-media: true
    width: 1280
    height: 720
    fig-dpi: 300
    # logo: figures/icg.png
revealjs-plugins:
  - pointer
editor: visual
draft: true
---

## План лекции

-   [Тест Стьюдента для зависимых выборок](t_test_dependent).

-   [Ошибки первого и второго рода и мощность тестов](#power).

-   Ограничения теста Стьюдента.

-   Проверки на нормальность.

-   Тест Манна-Уитни для независимых выборок и Вилкоксона для зависимых.

-   [Однофакторный дисперсионный анализ и поправка Тьюки.](#one_way_anova)

## Тест Стьюдента для зависимых выборок: формула {#t_test_dependent}

Двухвыборочный зависимый t-тест --- очень похож на одновыборочный t-тест, только для разницы между связанными значениями. Поскольку наша нулевая гипотеза звучит, что средние должны быть равны:

$H_0: \mu_1 = \mu_2$,

то при верности нулевой гипотезы $\mu_1 - \mu_2 = 0$

Тогда вместо $x$ подставим $d$ --- разницу (вектор разниц) между парами значений. Получаем такую формулу:

$$
t = \frac{\overline{x} - \mu} {s_x / \sqrt{N}} = \frac{\overline{d} - (\mu_1 - \mu_2)} {s_d / \sqrt{N}} = \frac{\overline{d} - 0} {s_d / \sqrt{N}}  = \frac{\overline{d}} {s_d / \sqrt{N}}
$$

## Тест Стьюдента для зависимых выборок: данные

Мы будем использовать [данные с курса по статистике Университета Шеффилда про эффективность диет](https://www.sheffield.ac.uk/polopoly_fs/1.570199!/file/stcp-Rdataset-Diet.csv).

```{r}
library(tidyverse)
diet <- readr::read_csv("https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/stcp-Rdataset-Diet.csv")
head(diet)
```

```{r}
#| output-location: slide
str(diet)
```

## Тест Сьюдента для зависимых выборок: код {style="font-size: 90%"}

Используем данные по первой диете:

```{r}
diet1 <- diet %>% 
  filter(Diet == 1)
```

Нам нужен тест Стьюдента для зависимых выборок, поскольку в группах одни и те же люди до диеты и после. По факту в этом тесте мы сравниваем разницу между весом после диеты и до диеты с 0.

```{r}
t.test(diet1$pre.weight, diet1$weight6weeks, paired = TRUE)
```

## Ошибки первого и второго рода {#power}

|                                   |                                       |
|-----------------------------------|---------------------------------------|
| Ошибка I рода: нашли то, чего нет | Ошибка II рода: не нашли то, что есть |

::: {style="position: absolute; top: 200px; left: 805px; width: 475px; height: 100px; background-color: rgba(209, 162, 142, 0.3); z-index: -1;"}
:::

::: {style="position: absolute; top: 200px; left: 330px; width: 475px; height: 100px; background-color: rgba(169, 209, 142, 0.3); z-index: -1;"}
:::

::: {style="position: absolute; top: 300px; left: 330px; width: 475px; height: 100px; background-color: rgba(209, 162, 142, 0.3); z-index: -1;"}
:::

::: {style="position: absolute; top: 300px; left: 805px; width: 475px; height: 100px; background-color: rgba(169, 209, 142, 0.3); z-index: -1;"}
:::

|                   | H~0~ верна (различий нет)          | H~0~ неверна (различие есть)        |
|-------------------|------------------------------------|-------------------------------------|
| Не отклонить H~0~ | True Negative                      | False Negative - ошибка II рода (β) |
| Отклонить H~0~    | False Positive - ошибка I рода (α) | True Positive                       |

Какая ошибка хуже? Зависит от ситуации.

Например, меня всегда учили, что при проведении RNA-seq эксперимента ошибка второго рода хуже (потратили ресурсы, а результаты не нашли).

В медицине обе ошибки могут стоить очень дорого.

## Ошибки первого и второго рода

![](images/image-1124886965.png)

## Ошибки первого и второго рода

![](images/image-54758192.png)

Дальнейшие несколько слайдов взяты из [презентации](https://varmara.github.io/linmodr/04_hypothesis_testing.html#55) Марины Варфоломеевой.

## Можно построить теоретические распределения при H~0~ и H~A~

![](images/image-540392203.png)

Распределение статистики, когда справедлива **H~0~**, нам уже знакомо --- его мы используем в тестах. Но может быть справедлива **H~A~** и ее тоже можно описать своим распределением.

При помощи этих распределений можно определить вероятность ошибок различных типов.

## Ошибка I рода --- найти различия там, где их нет

![](images/image-939957814.png)

$\alpha$ (критический уровень значимости) --- это вероятность ошибки I рода. Если

H~0~ справедлива, то при $\alpha = 0.05$ мы отвергаем ее с 5% вероятностью.

Чтобы снизить вероятность таких ошибок, можно уменьшить $\alpha$.

## Ошибка II рода ---не найти различий, где они есть

![](https://varmara.github.io/linmodr/04_hypothesis_testing_files/figure-html/unnamed-chunk-27-1.png)

$\beta$ --- вероятность ошибки II рода.

Считается, что допустимо $\beta \leq 0.2$, но часто про нее забывают.

Если мы уменьшаем α (график справа), то возрастает β.

## Мощность теста --- вероятность найти различия, если они есть

![](https://varmara.github.io/linmodr/04_hypothesis_testing_files/figure-html/unnamed-chunk-28-1.png)

$Power = 1 - \beta$ - мощность теста.\
Хорошо, когда мощность не меньше 0.8.

Мощность теста зависит от величины наблюдаемого эффекта (от величины различий) и размера выборки.

## Ограничения теста Стьюдента

::: incremental
-   Нормальность распределения - под вопросом.

-   Независимость наблюдений - очень важно.

-   Равенство дисперсий - необязательно для теста Велча.
:::

## Нужно ли нормальное распределение для t-теста?

Давайте сначала оценим вероятность ошибки первого рода, когда мы многократно (10000 раз) извлекаем две выборки объемом 30 значений из стандартного нормального распределения и сравниваем их t-тестом:

Генеральная совокупность одинаковая, следовательно мы ожидаем найти отличия не более чем в 5% случаев.

```{r}
mean(replicate(10000, t.test(rnorm(30), rnorm(30))$p.value) < 0.05)
```

Вероятность получить ошибку первого рода (то есть найти отличия, там где их на самом деле нет) примерно 0.05.

Ссылки: [1](https://koch-kir.medium.com/%D0%B8%D1%81%D1%82%D0%BE%D1%80%D0%B8%D1%8F-%D0%BE%D0%B4%D0%BD%D0%BE%D0%B3%D0%BE-%D0%BE%D0%B1%D0%BC%D0%B0%D0%BD%D0%B0-%D0%B8%D0%BB%D0%B8-%D1%82%D1%80%D0%B5%D0%B1%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%BA-%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D1%8E-%D0%B2-%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85-%D1%82%D0%B5%D1%81%D1%82%D0%B0%D1%85-55139a5558d), [2](https://pozdniakov.github.io/tidy_stats/320-ttest.html#sec-assumptions_ttest).

## Теперь такую же процедуру для логнормального распределения

Генеральная совокупность одинаковая, следовательно мы ожидаем найти отличия не более чем в 5% случаев.

```{r}
mean(replicate(10000, t.test(rlnorm(30), rlnorm(30))$p.value) < 0.05)
```

Вероятность ошибки первого рода даже меньше!

Что насчет графического способа определения p-value?

## Попробуем отрисовать qqplot для нормального распределения

qqplot - quantile-quantile plot.

```{r}
library(car)
set.seed(50)
samp <- rnorm(30)
qqPlot(samp)
```

В нормальном распределении точки должны располагаться на синей линии.

## Попробуем отрисовать гистограмму

```{r}
hist(samp)
```

Вывод: не всегда графический способ позволяет определить принадлежность данных нормальному распределению, поскольку при малых объемах выборки даже настоящее нормальное распределение может не выглядеть как нормальное.

## Тест Шапиро-Уилка (Shapiro-Wilk) для проверки на нормальность

```{r}
shapiro.test(samp)
```

В нашем случае p-value больше 0.05, что логично: мы взяли эту выборку именно из нормального распределения. Если p-value меньше уровня $\alpha$, который у нас стандартно 0.05, то мы можем отвергнуть нулевую гипотезу о том, что выборка взята из нормального распределения.

::: callout-warning
Однако тест Шапиро-Уилка это такой же статистический тест, как и другие, следовательно, чем больше выборка, тем с большей вероятностью он найдет отклонения от нормальности.
:::

## Непараметрические тесты

Тем не менее, бывают ситуации, когда тест Стьюдента неприменим, например в случае явных выбросов. В таком случае можно использовать непараметрический аналог - тест Манна-Уитни.

Кроме того, непараметрические методы подходят для интервальных и ранговых шкал, где арифметическое среднее не имеет физического смысла.

Непараметрические тесты не опираются на *параметры* заранее известных распределений (например нормального), следовательно, более устойчивы к нарушению предположений параметрических тестов.

## Тест Манна-Уитни (Mann-Whitney): теория {style="font-size: 90%"}

H~0~: $P(A > B) = 0.5$ вероятность того, что случайное число из распределения *A* больше, чем случайное число из распределения *B* равно 50%.

H~1~: $P(A > B) \neq 0.5$ вероятность, что случайное число из *A* больше чем *B* не равно 50%, следовательно распределения *A* и *B* отличаются сдвигом местоположения.

Иллюстрация:

```{r}
#| echo: false
df <- data.frame(A = rnorm(1000, 0, 1), B = rnorm(1000, 2, 1))
df %>% 
  pivot_longer(cols = A:B) %>% 
  ggplot(aes(value, fill = name))+
  geom_histogram(binwidth = 0.5, alpha = 0.5, color = 'black', position = 'identity')+
  scale_fill_manual(values=c("seagreen", "orange")) + 
  # theme_bw()+
  theme_classic()
```

## Тест Манна-Уитни (Mann-Whitney): формула {style="font-size: 90%"}

Числа из обеих выборок ранжируются, то есть расставляются по порядку и самому наименьшему числу присваивается ранг 1, следующему 2, и так далее. Затем вычисляется тестовая U-статистика.

Для независимых выборок - функция `wilcox.test()`, синтаксис такой же как и для `t.test()`:

```{r}
#| echo: false
wc3_units <- read_tsv('https://raw.githubusercontent.com/ubogoeva/tidyverse_tutorial/master/data/wc3_heroes.txt',
                      col_names = TRUE, 
                      na = '-', 
                      name_repair = 'minimal') %>% 
  janitor::clean_names() # для правильных названий колонок

wc3_units_armor <- wc3_units %>% 
  filter(armor_type == 'Heavy' | armor_type == 'Light')
```

```{r}
#| warning: true
wilcox.test(wc3_units_armor$hp ~ wc3_units_armor$armor_type)
```

В случае повторяющихся значений есть несколько стратегий вычисления рангов, в нашем случае присваются дробные ранги.

## Визуализация данных и проверка на нормальность распределения

```{r}
#| fig-width: 6
#| fig-height: 6
wc3_units_armor %>% 
  ggplot(aes(armor_type, hp))+
  geom_boxplot(width = 0.2)
```

```{r}
#| output-location: column
wc3_units_armor %>% 
  filter(armor_type == 'Heavy') %>% 
  pull(hp) %>% 
  shapiro.test()
```

## Тест Вилкоксона (Wilcoxon) для зависимых выборок

Непараметрический аналог теста Стьюдента для зависимых выборок.

```{r}
wilcox.test(diet1$pre.weight, diet1$weight6weeks, paired = TRUE)
```

У непараметрических тестов меньше мощность из-за редуцирования информации при переводе в ранги.

```{r}
# вспомним результат t-теста
t.test(diet1$pre.weight, diet1$weight6weeks, paired = TRUE)$p.value
```

## Дисперсионный анализ (ANOVA)

Дисперсионный анализ (analysis of variance, ANOVA) --- метод для сравнения средних в трех и более группах.

Виды дисперсионного анализа:

-   Однофакторный (one-way)

-   Двухфакторный (two-way)

-   MANOVA (Multivariate analysis of variance)

-   ANCOVA

Мы будем подробно рассматривать первые два.

# Однофакторный дисперсионный анализ {#one_way_anova}

## Однофакторный дисперсионный анализ: данные {style="font-size: 90%"}

Допустим, мы хотим сравнить средюю потерю веса для различных диет.

Терминология: потеря веса является *зависимой переменной*, тип диеты - *независимая переменная*. Зависимая переменная - непрерывная, независимая - категориальная.

**1 этап: формулировка нулевой и альтернативной гипотезы.**

H~0~: все средние равны. $\mu_1 = \mu_2 = \mu_3$

H~1~: хотя бы одно среднее не равно остальным.

Для начала проверим, сколько наблюдений для каждой из диет:

```{r}
diet %>% 
  count(Diet)
```

3 группы. Данные сбалансированы (то есть примерно одинаковое количество наблюдений для каждой группы), это важно для дисперсионного анализа.

## Однофакторный дисперсионный анализ: подготовка данных

```{r}
slice_sample(diet, n = 5)
```

Нам нужно создать переменную, отражающую потерю веса, перекодировать тип диеты в фактор и удалить пропущенные значения.

```{r}
diet <- diet %>%
  mutate(weight_loss = weight6weeks - pre.weight,
         Dietf = factor(Diet, labels = LETTERS[1:3]),
         Person = factor(Person)) %>%
  drop_na()
```

## Визуализация данных

Попробуем отрисовать боксплот:

```{r}
diet %>% 
  ggplot(aes(Dietf, weight_loss, fill = Dietf))+
  geom_boxplot()
```

Похоже, что диета C отличается от остальных. Давайте теперь проверим статистически!

## Однофакторный дисперсионный анализ: код

Используем встроенную в base R функцию `aov()` (analysis of variance).

```{r}
aov(weight_loss ~ Dietf, data = diet)
```

## Однофакторный дисперсионный анализ: формула

|                 | Степени свободы  | Суммы квадратов           | Средние квадраты                | F-статистика              |
|-----------------|------------------|---------------------------|---------------------------------|---------------------------|
| Межгрупповые    | $df_{b} = J - 1$ | $SS_{b}$                  | $MS_{b} =\frac{SS_{b}}{df_{b}}$ | $F=\frac{MS_{b}}{MS_{w}}$ |
| Внутригрупповые | $df_{w} = N - J$ | $SS_{w}$                  | $MS_{w} =\frac{SS_{w}}{df_{w}}$ |                           |
| Общие           | $df_{t} = N - 1$ | $SS_{t}= SS_{b} + SS_{w}$ |                                 |                           |

$J$ означает количество групп, $N$ - общее количество наблюдений во всех группах.

## Однофакторный дисперсионный анализ: формула

|                 | Степени свободы  | Суммы квадратов                                                                       | Средние квадраты                | F-статистика              |
|-----------------|------------------|---------------------------------------------------------------------------------------|---------------------------------|---------------------------|
| Межгрупповые    | $df_{b} = J - 1$ | $SS_{b}= \sum\limits_{j=1}^J \sum\limits_{i=1}^{n_j} (\overline{x_j}-\overline{x})^2$ | $MS_{b} =\frac{SS_{b}}{df_{b}}$ | $F=\frac{MS_{b}}{MS_{w}}$ |
| Внутригрупповые | $df_{w} = N - J$ | $SS_{w}= \sum\limits_{j=1}^J \sum\limits_{i=1}^{n_j} (x_{ij}-\overline{x_j})^2$       | $MS_{w} =\frac{SS_{w}}{df_{w}}$ |                           |
| Общие           | $df_{t} = N - 1$ | $SS_{t}= \sum\limits_{j=1}^J \sum\limits_{i=1}^{n_j} (x_{ij}-\overline{x})^2$         |                                 |                           |

$n_j$ означает количество наблюдений в группе $j$, а $x_{ij}$ - наблюдение под номером $i$ в группе $j$.

## Однофакторный дисперсионный анализ: формула

Вариабельность обозначается $SS$ и означает "сумму квадратов" (sum of squares) - почти тоже самое, что и дисперсия, только мы не делим в конце на количество наблюдений:

$$
SS = \sum\limits_{i=1}^{n_j} (x_{i}-\overline{x})^2
$$

Попробуем рассчитать самостоятельно по формулам, используя R.

## Однофакторный дисперсионный анализ: код

Сохраним результат вызова `aov()` в переменную `fit_diet`, чтобы вызвать `summary()`.

```{r}
fit_diet <- aov(weight_loss ~ Dietf, data = diet)
summary(fit_diet)
```

p-value \< 0.05, следовательно, мы отклоняем нулевую гипотезу. Какие диеты отличаются между собой?

## Постхок-тесты для дисперсионного анализа {style="font-size: 90%"}

Рекомендую использовать поправку Тьюки для определения, какие именно группы различаются.

Поправка Тьюки похожа на тест Стьюдента, однако различается формула расчета стандартного отклонения в знаменателе, поэтому учитывается вклад всех групп.

Функция `TukeyHSD()` принимает на вход объект класса `aov`.

```{r}
TukeyHSD(fit_diet)
```

Итак, мы видим, что диета C отличается от A и от B, диеты A и B между собой не различаются.

В литературе по статистике можно встретить "правило", якобы нельзя использовать поправку Тьюки перед выполнением ановы, но на самом деле это не так, если задача узнать, какие групры различаются, то можно использовать сразу Тьюки.

## Спасибо за внимание!

Если понравилось, переходите по [ссылке](https://www.tinkoff.ru/rm/ubogoeva.elena1/TSRBI31474):

![](images/qrcode.png)
