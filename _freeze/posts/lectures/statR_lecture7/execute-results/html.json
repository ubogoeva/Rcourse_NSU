{
  "hash": "093c025ca9183c3e78c03cac740fd877",
  "result": {
    "markdown": "---\ntitle: \"Язык программирования R для анализа данных: лекция 7\"\nsubtitle: 'Введение в статистику вывода: продолжение'\nauthor: \"Elena U\"\n#date: \"Created on 01 April, 2023\"\nexecute:\n  echo: true\n  output: true\nformat: \n  revealjs:\n    slide-number: c/t\n    show-slide-number: all\n    # mainfont: Arial\n    # fontsize: 14px\n    theme: [default, custom.scss]\n    chalkboard: \n      buttons: true\n    # theme: [serif]\n    # mouse-wheel: true\n    auto-play-media: true\n    width: 1280\n    height: 720\n    fig-dpi: 300\n    # logo: figures/icg.png\nrevealjs-plugins:\n  - pointer\neditor: visual\ndraft: true\n---\n\n\n## План лекции\n\n-   Параметры и статистики.\n\n-   Виды распределений: функции плотности вероятности (probability density/mass functions), кумулятивные функции распределения.\n\n-   Стандартное нормальное распределение, центральная предельная теорема.\n\n-   Стандартная ошибка и доверительный интервал.\n\n-   Алгоритм статистического вывода на примере Z-теста.\n\n-   Тест Стьюдента.\n\n## Параметры и статистики\n\nPopulation - генеральная совокупность.\n\nSample - выборка.\n\n|                          |                                                                          |\n|---------------------|:--------------------------------------------------|\n| [P]{.underline}opulation | [P]{.underline}arameter (обозначают греческими буквами: $\\mu$, $\\sigma$. |\n| [S]{.underline}ample     | [S]{.underline}tatistics (обозначают например $\\overline{x}$, $sd$)      |\n\nНапример, у стандартного нормального распределения среднее $\\mu$ 0 и стандартное отклонение $\\sigma$ 1, и эти значения являются *параметрами*, поскольку описывают теоретическое распределение (генеральную совокупность).\n\nНапример, в датасете `iris` среднее `Sepal.Length` равно 5.84, а стандартное отклонение 0.828, и эти значения являются *статистиками* (описывают выборку).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(iris$Sepal.Length)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 5.843333\n```\n:::\n\n```{.r .cell-code}\nsd(iris$Sepal.Length)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.8280661\n```\n:::\n:::\n\n\n## Полезные функции для генерации различных распределений\n\nМожно посмотреть в cheatsheet по base R.\n\n![](https://pozdniakov.github.io/tidy_stats/images/rdists.PNG){width=\"613\"}\n\nНаиболее полезные функции: density (`d*()`), cumulative distribution (`p*()`) и random (`r*()`).\n\n::: {.callout-tip appearance=\"simple\"}\nСо списком всех доступных в base R распределений можно ознакомиться, вызвав\n\n\n::: {.cell}\n\n```{.r .cell-code}\n?Distributions\n```\n:::\n\n:::\n\n## Стандартное нормальное распределение\n\nСтандартное нормальное распределение имеет среднее 0 и стандартное отклонение 1. Важно отметить, что здесь мы говорим о *параметрах* генеральной совокупности, а не о статистиках.\n\n![](https://pozdniakov.github.io/tidy_stats/images/normalstandard.jpg)\n\n## Функция плотности вероятности нормального распределения: `dnorm()`\n\n::: incremental\n-   Density function\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    dnorm(0)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    [1] 0.3989423\n    ```\n    :::\n    \n    ```{.r .cell-code}\n    # что получится, если запустить dnorm(1)?\n    ```\n    :::\n\n\n-   \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    dnorm(1)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    [1] 0.2419707\n    ```\n    :::\n    \n    ```{.r .cell-code}\n    # а если запустить dnorm(-1)?\n    ```\n    :::\n\n\n-   \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    dnorm(-1)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    [1] 0.2419707\n    ```\n    :::\n    :::\n\n:::\n\n## Функция плотности вероятности стандартного нормального распределения {style=\"font-size: 80%\"}\n\n::: {.callout-note appearance=\"simple\"}\nЗабавный момент: для дискретных распределений называется *probability mass function*, для непрерывных - *probability density function*, на русский язык переводится одинаково: функция плотности вероятности.\n:::\n\nДавайте отрисуем функцию плотности вероятности стандартного нормального распределения с помощью `dnorm()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nvec <- seq(-3, 3, 0.01)\nplot(vec, dnorm(vec))\n```\n\n::: {.cell-output-display}\n![](statR_lecture7_files/figure-revealjs/unnamed-chunk-6-1.png){width=3000}\n:::\n:::\n\n\n## Функция плотности вероятности шкалы IQ\n\n\n::: {.cell}\n\n```{.r .cell-code}\niq <- seq(50, 150, 0.1)\nplot(iq, dnorm(iq, mean = 100, sd = 15))\n```\n\n::: {.cell-output-display}\n![](statR_lecture7_files/figure-revealjs/unnamed-chunk-7-1.png){width=3000}\n:::\n:::\n\n\nШкала IQ отнормирована таким образом, чтобы среднее генеральной совокупности было равно 100, а стандартное отклонение 15.\n\n## `pnorm()` - кумулятивная функция распределения (cumulative density function)\n\nНа примере стандартного нормального распределения.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(vec, pnorm(vec))\n```\n\n::: {.cell-output-display}\n![](statR_lecture7_files/figure-revealjs/unnamed-chunk-8-1.png){width=3000}\n:::\n:::\n\n\n`pnorm()` отражает вероятность получить такое же или меньшее значение в нормальном распределении (в данном случае в стандартном).\n\n## `pnorm()` - кумулятивная функция распределения (cumulative density function)\n\nНа примере шкалы IQ.\n\n::: incremental\n-   Чему будет равно значение `pnorm(100)` для этой шкалы? То есть какая вероятность получить значение меньше чем 100?\n\n-   \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    pnorm(100, mean = 100, sd = 15) # не забываем прописывать mean, sd\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    [1] 0.5\n    ```\n    :::\n    :::\n\n\n-   Среднее равно 100, следовательно -\\> пояснение на графике\n\n-   Чему равно значение `pnorm(130)` для шкалы IQ?\n\n-   \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    pnorm(130, mean = 100, sd = 15)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    [1] 0.9772499\n    ```\n    :::\n    :::\n\n:::\n\n## `rnorm()` - функция для генерации случайных значений из заданного распределения\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42) # для воспроизводимости 'рандома'\nrnorm(30)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  1.37095845 -0.56469817  0.36312841  0.63286260  0.40426832 -0.10612452\n [7]  1.51152200 -0.09465904  2.01842371 -0.06271410  1.30486965  2.28664539\n[13] -1.38886070 -0.27878877 -0.13332134  0.63595040 -0.28425292 -2.65645542\n[19] -2.44046693  1.32011335 -0.30663859 -1.78130843 -0.17191736  1.21467470\n[25]  1.89519346 -0.43046913 -0.25726938 -1.76316309  0.46009735 -0.63999488\n```\n:::\n\n```{.r .cell-code}\nrnorm(30)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n [1]  0.45545012  0.70483734  1.03510352 -0.60892638  0.50495512 -1.71700868\n [7] -0.78445901 -0.85090759 -2.41420765  0.03612261  0.20599860 -0.36105730\n[13]  0.75816324 -0.72670483 -1.36828104  0.43281803 -0.81139318  1.44410126\n[19] -0.43144620  0.65564788  0.32192527 -0.78383894  1.57572752  0.64289931\n[25]  0.08976065  0.27655075  0.67928882  0.08983289 -2.99309008  0.28488295\n```\n:::\n:::\n\n\nСид нужно фиксировать каждый раз перед запуском чего-то зависящего от случайности.\n\n## Вычисление стандартного отклонения\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(50) # для фиксации рандома\nsamp <- rnorm(100, mean = 100, sd = 15)\nsqrt(sum((samp - mean(samp)) ^ 2) / (length(samp))) # совпадает ли с результатом функции sd?\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 14.81449\n```\n:::\n\n```{.r .cell-code}\nsd(samp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 14.88912\n```\n:::\n:::\n\n\nПочему не совпадает?\n\n$$\nsd = \\sqrt{var} =\\sqrt{\\frac{\\sum_{i=1}^n(x_i - \\overline{x})^2}{n}}\n$$\n\n## Формула стандартного отклонения\n\nВо встроенной функции `sd()`, которая опирается на функцию `var()`, в формуле n-1 в знаменателе.\n\n$$\nsd = \\sqrt{var} =\\sqrt{\\frac{\\sum_{i=1}^n(x_i - \\overline{x})^2}{n - 1}}\n$$\n\nТакая оценка стандартного отклонения называется несмещенной (unbiased) оценкой.\n\nПочему n-1 в знаменателе -\\> объяснение на графике.\n\n## Значение центральной предельной теоремы\n\nМысленный эксперимент: многократно извлекаем выборки из генеральной совокупности, считаем средние по выборкам.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamp_means <- replicate(1000, mean(rnorm(100, mean = 100, sd = 15)))\nhist(samp_means, breaks = 30)\n```\n\n::: {.cell-output-display}\n![](statR_lecture7_files/figure-revealjs/unnamed-chunk-13-1.png){width=3000}\n:::\n:::\n\n\nРаспределение средних, извлеченных из нормального распределения, примерно нормальное. Это неудивительно, попробуем теперь в качестве генеральной совокупности использовать лог-нормальное распределение.\n\n## Лог-нормальное распределение\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(rlnorm(100), breaks = 30)\n```\n\n::: {.cell-output-display}\n![](statR_lecture7_files/figure-revealjs/unnamed-chunk-14-1.png){width=3000}\n:::\n:::\n\n\n## Распределение средних лог-нормального распределения {style=\"font-size: 90%\"}\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsamp_means_log <- replicate(1000, mean(rlnorm(100)))\nhist(samp_means_log, breaks = 30)\n```\n\n::: {.cell-output-display}\n![](statR_lecture7_files/figure-revealjs/unnamed-chunk-15-1.png){width=3000}\n:::\n:::\n\n\nА вот распределение средних из изначально не-нормального распределение тоже похоже на нормальное распределение! Это получается благодаря центральной предельной теореме.\n\n[Шайни апп для центральной предельной теоремы](https://gallery.shinyapps.io/CLT_mean/)\n\n## Выведение стандартной ошибки\n\n::: incremental\n-   Среднее выборочного распределения средних близко к популяционному среднему:\n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    mean(samp_means)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    [1] 100.0026\n    ```\n    :::\n    :::\n\n\n-   Чему же равно стандартное отклонение средних?\n\n-   \n\n\n    ::: {.cell}\n    \n    ```{.r .cell-code}\n    sd(samp_means)\n    ```\n    \n    ::: {.cell-output .cell-output-stdout}\n    ```\n    [1] 1.503984\n    ```\n    :::\n    :::\n\n\n-   Оно примерно равно стандартному отклонению генеральной совокупности деленное на 10 - корень из размера выборки (100).\n:::\n\n## Формула стандартной ошибки\n\n$$\n\\sigma_{\\overline{x}}= \\frac{\\sigma} {\\sqrt{n}}\n$$\n\nСтандартное отклонение выборочного распределения средних называется еще стандартной ошибкой или standard error of the mean (s.e.m.). Нередко стандартную ошибку используют на графиках в качестве error bars.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nsem <- 15/sqrt(length(samp))\nsem\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.5\n```\n:::\n:::\n\n\nПоскольку обычно мы не знаем истинное стандартное отклонение генеральной совокупности ($\\sigma$), то используем стандартное отклонение выборки $sd$.\n\n$$\ns_{\\overline{x}}= \\frac{sd} {\\sqrt{n}}\n$$\n\n## Доверительный интервал\n\nМы хотим поймать симметрично 95% от площади под кривой. Для этого нам нужно отбросить по 2.5% с обоих сторон. Эти 2.5% соответствуют примерно двум стандартным отклонениям от среднего. Если быть точнее, то 1.96. Если быть еще точнее:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nqnorm(0.975)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.959964\n```\n:::\n\n```{.r .cell-code}\nzcr <- qnorm(1 - (1 - 0.95)/2)\nzcr\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 1.959964\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nsem <- 15/sqrt(length(samp))\nmean(samp) - sem*zcr #нижняя граница\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 95.35715\n```\n:::\n\n```{.r .cell-code}\nmean(samp) + sem*zcr #верхняя граница\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 101.237\n```\n:::\n:::\n\n\n## Доверительный интервал\n\nПопробуем отрисовать доверительные интервалы:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\nsample_size <- 100\nset.seed(40)\nci_simulations <- tibble(\n  m = replicate(sample_size, mean(rnorm(sample_size, mean = 100, sd = 15))),\n  se = 15/sqrt(sample_size),\n  lower = m - se*zcr,\n  higher = m + se*zcr,\n  parameter_inside = lower<100 & higher>100\n)\nmany_ci_gg <- ggplot(data = ci_simulations, aes(x = 1:sample_size,y = m)) +\n  geom_pointrange(aes(ymin = lower,ymax = higher,colour = parameter_inside))+\n  geom_hline(yintercept = 100)+\n  coord_flip() +\n  theme_minimal()\n```\n:::\n\n\n## Визуализация доверительных интервалов\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmany_ci_gg\n```\n\n::: {.cell-output-display}\n![](statR_lecture7_files/figure-revealjs/unnamed-chunk-22-1.png){width=3000}\n:::\n:::\n\n\nЕще одна [Визуализация доверительных интервалов](http://rpsychologist.com/d3/CI/)\n\n## Алгоритм статистического вывода\n\n1.  Формулировка нулевой и альтернативной гипотезы.\n\n2.  Вычисление тестовых статистик.\n\n3.  Подсчет p-value как площади под кривой выборочного распределения тестовых статистик.\n\n4.  Вывод: отклоняем или не отклоняем нулевую гипотезу.\n\n# Разберем на примере z-теста\n\n## Формулировка нулевой и альтернативной гипотезы:\n\n-   $H_0$: $m = \\mu$ нулевая гипотеза, например, что среднее выборки статистически не отличается от среднего генеральной совокупности\n\n-   $H_1: m \\neq \\mu$ альтернативная гипотеза, о том что средние не равны\n\n## Вычисление тестовой статистики\n\nФормула z-скора\n\n$$\nz = \\frac{m - \\mu_{H_0}}{\\sigma/\\sqrt{N}},\n$$\n\nгде m - среднее выборки, $\\mu_{H_0}$ - среднее генеральной совокупности, $\\sigma$ - стандартное отклонение генеральной совокупности, $N$ - размер выборки.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nset.seed(42) # для фиксации рандома\nsamp <- rnorm(100, mean = 100, sd = 15)\nm <- mean(samp)\nm\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 100.4877\n```\n:::\n\n```{.r .cell-code}\nsem <- 15/sqrt(length(samp))\nz <- (m - 100)/sem\nz\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3251482\n```\n:::\n:::\n\n\n## Вычисление p-value\n\n\n::: {.cell}\n\n```{.r .cell-code}\npnorm(z)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6274655\n```\n:::\n:::\n\n\n`pnorm()` считает от минус бесконечности до заданного числа, а нам нужно наоборот --- от заданного числа до плюс бесконечности, потому что $z$ больше нуля. Этого можно добиться вычитанием из 1.\n\nПоскольку мы не знаем в какую сторону у нас ожидается эффект, то нужно еще учесть симметричную площадь под кривой.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n1 - pnorm(z)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3725345\n```\n:::\n\n```{.r .cell-code}\np_value <- (1 - pnorm(z))*2\np_value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7450689\n```\n:::\n:::\n\n\nМного это или мало? Какой делаем вывод?\n\n## Вывод\n\np-value \\> 0.05, порогового значения $\\alpha$, следовательно мы НЕ отклоняем нулевую гипотезу.\n\n## Тест Стьюдента или t-test\n\nНа практике z-тест не используется, потому что предполагает, что мы знаем стандартное отклонение в генеральной совокупности. Обычно это не так, поэтому мы оцениваем стандартное отклонение в генеральной совокупности на основе стандартного отклонения по выборке.\n\nЭто приводит к тому, что тестовая статистика уже не распределена нормально, а распределена согласно t-распределению. Статистика называется t-статистикой.\n\n$$\nt = \\frac{\\overline{x} - \\mu} {s_x / \\sqrt{N}}\n$$\n\n## Распределение Стьюдента или t-распределение\n\nЕсть параметр степеней свободы: размер выборки -1\n\n![](https://pozdniakov.github.io/tidy_stats/320-ttest_files/figure-html/unnamed-chunk-1-1.png)\n\nt-распределение имеет более тяжелые хвосты.\n\nПри размере выборке стремящемуся к бесконечности, t-распределение стремится к нормальному.\n\n## Проведение теста Стьюдента\n\nФормулировка нулевой и альтернативной гипотезы не изменилась.\n\nТеперь в качестве тестовой статистики вычисляем t-статистику по формуле:\n\n$$\nt = \\frac{\\overline{x} - \\mu} {s_x / \\sqrt{N}}\n$$\n\n\n::: {.cell}\n\n```{.r .cell-code}\nm <- mean(samp)\nsem <- sd(samp)/sqrt(length(samp)) # разница на этом шаге\nt <- (m - 100)/sem\nt\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3122351\n```\n:::\n\n```{.r .cell-code}\n(m - 100) / (15/sqrt(100)) # это z-score, значения близки\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3251482\n```\n:::\n:::\n\n\n## Вычисление p-value в тесте Стьюдента\n\nТеперь вычисляем p-value как площадь под кривой распределения t-статистики. Для этого используем уже не `pnorm()`, а `pt()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\npt(t, df = length(samp) - 1) # здесь различие от z-теста\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.6222407\n```\n:::\n\n```{.r .cell-code}\n1 - pt(t, df = length(samp) - 1) # односторонний\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.3777593\n```\n:::\n\n```{.r .cell-code}\n(1 - pt(t, df = length(samp) - 1))*2 # двусторонний\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.7555186\n```\n:::\n\n```{.r .cell-code}\nt.test(samp, mu = 100) # проверка\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tOne Sample t-test\n\ndata:  samp\nt = 0.31224, df = 99, p-value = 0.7555\nalternative hypothesis: true mean is not equal to 100\n95 percent confidence interval:\n  97.38831 103.58714\nsample estimates:\nmean of x \n 100.4877 \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\nКартинка Ивана Позднякова с описанием этапов статистического вывода\n\n![](images/image-1909717986.png)\n\n## \n\nТест Стьюдента для сравнения двух выборок\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwc3_units_armor <- wc3_units %>% \n  filter(armor_type == 'Heavy' | armor_type == 'Light')\nt.test(wc3_units_armor$hp ~ wc3_units_armor$armor_type)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  wc3_units_armor$hp by wc3_units_armor$armor_type\nt = -2.3602, df = 21.493, p-value = 0.02778\nalternative hypothesis: true difference in means between group Heavy and group Light is not equal to 0\n95 percent confidence interval:\n -536.65167  -34.28877\nsample estimates:\nmean in group Heavy mean in group Light \n           533.6207            819.0909 \n```\n:::\n:::\n\n\n------------------------------------------------------------------------\n\nМожно в функцию `t.test()` подавать два вектора:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(seq(1, 10, 0.1), seq(5, 12, 0.2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWelch Two Sample t-test\n\ndata:  seq(1, 10, 0.1) and seq(5, 12, 0.2)\nt = -6.7082, df = 80.014, p-value = 2.564e-09\nalternative hypothesis: true difference in means is not equal to 0\n95 percent confidence interval:\n -3.889981 -2.110019\nsample estimates:\nmean of x mean of y \n      5.5       8.5 \n```\n:::\n:::\n\n\n## Тест Стьюдента и тест Велча {style=\"font-size:90%\"}\n\nНа самом деле по умолчанию в R запускается тест Велча, поскольку предполагается, что дисперсии двух выборок не равны\n\nФормула теста Стьюдента:\n\n$$\nt = \\frac{\\overline{X_1}-\\overline{X_2}}{s_x\\sqrt{\\frac{1}{n_1} + \\frac{1}{n_2}}},\ns_x = \\sqrt{\\frac{(n_1 - 1)s_1^2 + (n_2 - 1)s_2^2}{n_1 + n_2 - 2}}\n$$\n\nЧтобы запустить именно тест Стьюдента, можно использовать аргумент `var.equal = TRUE`\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(wc3_units_armor$hp ~ wc3_units_armor$armor_type, \n       var.equal = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tTwo Sample t-test\n\ndata:  wc3_units_armor$hp by wc3_units_armor$armor_type\nt = -2.1765, df = 38, p-value = 0.0358\nalternative hypothesis: true difference in means between group Heavy and group Light is not equal to 0\n95 percent confidence interval:\n -550.98551  -19.95493\nsample estimates:\nmean in group Heavy mean in group Light \n           533.6207            819.0909 \n```\n:::\n:::\n\n\nОднако это делать не рекомендуется, поскольку при равных дисперсиях тест Стьюдента не будет сильно отличаться от теста Велча, а при разных тест Велча точнее.\n\n------------------------------------------------------------------------\n\nФормула теста Велча:\n\n$$\nt = \\frac{\\overline{X}_1 - \\overline{X}_2}{\\sqrt{\\frac{s_1^2}{n_1} + \\frac{s_2^2}{n_2}}}\n$$\n\nКоличество степеней свободы:\n\n$$\ndf = \\frac{(s_1^2/n_1 + s_2^2 / n_2)^2}{(s_1^2/n_1)^2/(n_1-1) + (s_2^2/n_2)^2/(n_2-1)}\n$$\n\nПо умолчанию рекомендуется использовать тест Велча.\n",
    "supporting": [
      "statR_lecture7_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}