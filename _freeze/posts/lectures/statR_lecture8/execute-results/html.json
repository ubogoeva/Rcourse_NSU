{
  "hash": "44a7e76152f8241be741a20a965e1c7a",
  "result": {
    "markdown": "---\ntitle: \"Язык программирования R для анализа данных: лекция 8\"\nsubtitle: 'Тест Стьюдента, Манна-Уитни'\nauthor: \"Elena U\"\n#date: \"Created on 01 April, 2023\"\nexecute:\n  echo: true\n  output: true\nformat: \n  revealjs:\n    slide-number: c/t\n    show-slide-number: all\n    # mainfont: Arial\n    # fontsize: 14px\n    theme: [default, custom.scss]\n    chalkboard: \n      buttons: true\n    # theme: [serif]\n    # mouse-wheel: true\n    auto-play-media: true\n    width: 1280\n    height: 720\n    fig-dpi: 300\n    # logo: figures/icg.png\nrevealjs-plugins:\n  - pointer\neditor: visual\ndraft: true\n---\n\n\n## План лекции\n\n-   [Тест Стьюдента для зависимых выборок](t_test_dependent).\n\n-   [Ошибки первого и второго рода и мощность тестов](#power).\n\n-   Ограничения теста Стьюдента.\n\n-   Проверки на нормальность.\n\n-   Тест Манна-Уитни для независимых выборок и Вилкоксона для зависимых.\n\n-   [Однофакторный дисперсионный анализ и поправка Тьюки.](#one_way_anova)\n\n## Тест Стьюдента для зависимых выборок: формула {#t_test_dependent}\n\nДвухвыборочный зависимый t-тест --- очень похож на одновыборочный t-тест, только для разницы между связанными значениями. Поскольку наша нулевая гипотеза звучит, что средние должны быть равны:\n\n$H_0: \\mu_1 = \\mu_2$,\n\nто при верности нулевой гипотезы $\\mu_1 - \\mu_2 = 0$\n\nТогда вместо $x$ подставим $d$ --- разницу (вектор разниц) между парами значений. Получаем такую формулу:\n\n$$\nt = \\frac{\\overline{x} - \\mu} {s_x / \\sqrt{N}} = \\frac{\\overline{d} - (\\mu_1 - \\mu_2)} {s_d / \\sqrt{N}} = \\frac{\\overline{d} - 0} {s_d / \\sqrt{N}}  = \\frac{\\overline{d}} {s_d / \\sqrt{N}}\n$$\n\n## Тест Стьюдента для зависимых выборок: данные\n\nМы будем использовать [данные с курса по статистике Университета Шеффилда про эффективность диет](https://www.sheffield.ac.uk/polopoly_fs/1.570199!/file/stcp-Rdataset-Diet.csv).\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(tidyverse)\ndiet <- readr::read_csv(\"https://raw.githubusercontent.com/Pozdniakov/tidy_stats/master/data/stcp-Rdataset-Diet.csv\")\nhead(diet)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 6 × 7\n  Person gender   Age Height pre.weight  Diet weight6weeks\n   <dbl>  <dbl> <dbl>  <dbl>      <dbl> <dbl>        <dbl>\n1     25     NA    41    171         60     2         60  \n2     26     NA    32    174        103     2        103  \n3      1      0    22    159         58     1         54.2\n4      2      0    46    192         60     1         54  \n5      3      0    55    170         64     1         63.3\n6      4      0    33    171         64     1         61.1\n```\n:::\n:::\n\n::: {.cell output-location='slide'}\n\n```{.r .cell-code}\nstr(diet)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nspc_tbl_ [78 × 7] (S3: spec_tbl_df/tbl_df/tbl/data.frame)\n $ Person      : num [1:78] 25 26 1 2 3 4 5 6 7 8 ...\n $ gender      : num [1:78] NA NA 0 0 0 0 0 0 0 0 ...\n $ Age         : num [1:78] 41 32 22 46 55 33 50 50 37 28 ...\n $ Height      : num [1:78] 171 174 159 192 170 171 170 201 174 176 ...\n $ pre.weight  : num [1:78] 60 103 58 60 64 64 65 66 67 69 ...\n $ Diet        : num [1:78] 2 2 1 1 1 1 1 1 1 1 ...\n $ weight6weeks: num [1:78] 60 103 54.2 54 63.3 61.1 62.2 64 65 60.5 ...\n - attr(*, \"spec\")=\n  .. cols(\n  ..   Person = col_double(),\n  ..   gender = col_double(),\n  ..   Age = col_double(),\n  ..   Height = col_double(),\n  ..   pre.weight = col_double(),\n  ..   Diet = col_double(),\n  ..   weight6weeks = col_double()\n  .. )\n - attr(*, \"problems\")=<externalptr> \n```\n:::\n:::\n\n\n## Тест Сьюдента для зависимых выборок: код {style=\"font-size: 90%\"}\n\nИспользуем данные по первой диете:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiet1 <- diet %>% \n  filter(Diet == 1)\n```\n:::\n\n\nНам нужен тест Стьюдента для зависимых выборок, поскольку в группах одни и те же люди до диеты и после. По факту в этом тесте мы сравниваем разницу между весом после диеты и до диеты с 0.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nt.test(diet1$pre.weight, diet1$weight6weeks, paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tPaired t-test\n\ndata:  diet1$pre.weight and diet1$weight6weeks\nt = 7.2168, df = 23, p-value = 2.397e-07\nalternative hypothesis: true mean difference is not equal to 0\n95 percent confidence interval:\n 2.354069 4.245931\nsample estimates:\nmean difference \n            3.3 \n```\n:::\n:::\n\n\n## Ошибки первого и второго рода {#power}\n\n|                                   |                                       |\n|-----------------------------------|---------------------------------------|\n| Ошибка I рода: нашли то, чего нет | Ошибка II рода: не нашли то, что есть |\n\n::: {style=\"position: absolute; top: 200px; left: 805px; width: 475px; height: 100px; background-color: rgba(209, 162, 142, 0.3); z-index: -1;\"}\n:::\n\n::: {style=\"position: absolute; top: 200px; left: 330px; width: 475px; height: 100px; background-color: rgba(169, 209, 142, 0.3); z-index: -1;\"}\n:::\n\n::: {style=\"position: absolute; top: 300px; left: 330px; width: 475px; height: 100px; background-color: rgba(209, 162, 142, 0.3); z-index: -1;\"}\n:::\n\n::: {style=\"position: absolute; top: 300px; left: 805px; width: 475px; height: 100px; background-color: rgba(169, 209, 142, 0.3); z-index: -1;\"}\n:::\n\n|                   | H~0~ верна (различий нет)          | H~0~ неверна (различие есть)        |\n|-------------------|------------------------------------|-------------------------------------|\n| Не отклонить H~0~ | True Negative                      | False Negative - ошибка II рода (β) |\n| Отклонить H~0~    | False Positive - ошибка I рода (α) | True Positive                       |\n\nКакая ошибка хуже? Зависит от ситуации.\n\nНапример, меня всегда учили, что при проведении RNA-seq эксперимента ошибка второго рода хуже (потратили ресурсы, а результаты не нашли).\n\nВ медицине обе ошибки могут стоить очень дорого.\n\n## Ошибки первого и второго рода\n\n![](images/image-1124886965.png)\n\n## Ошибки первого и второго рода\n\n![](images/image-54758192.png)\n\nДальнейшие несколько слайдов взяты из [презентации](https://varmara.github.io/linmodr/04_hypothesis_testing.html#55) Марины Варфоломеевой.\n\n## Можно построить теоретические распределения при H~0~ и H~A~\n\n![](images/image-540392203.png)\n\nРаспределение статистики, когда справедлива **H~0~**, нам уже знакомо --- его мы используем в тестах. Но может быть справедлива **H~A~** и ее тоже можно описать своим распределением.\n\nПри помощи этих распределений можно определить вероятность ошибок различных типов.\n\n## Ошибка I рода --- найти различия там, где их нет\n\n![](images/image-939957814.png)\n\n$\\alpha$ (критический уровень значимости) --- это вероятность ошибки I рода. Если\n\nH~0~ справедлива, то при $\\alpha = 0.05$ мы отвергаем ее с 5% вероятностью.\n\nЧтобы снизить вероятность таких ошибок, можно уменьшить $\\alpha$.\n\n## Ошибка II рода ---не найти различий, где они есть\n\n![](https://varmara.github.io/linmodr/04_hypothesis_testing_files/figure-html/unnamed-chunk-27-1.png)\n\n$\\beta$ --- вероятность ошибки II рода.\n\nСчитается, что допустимо $\\beta \\leq 0.2$, но часто про нее забывают.\n\nЕсли мы уменьшаем α (график справа), то возрастает β.\n\n## Мощность теста --- вероятность найти различия, если они есть\n\n![](https://varmara.github.io/linmodr/04_hypothesis_testing_files/figure-html/unnamed-chunk-28-1.png)\n\n$Power = 1 - \\beta$ - мощность теста.\\\nХорошо, когда мощность не меньше 0.8.\n\nМощность теста зависит от величины наблюдаемого эффекта (от величины различий) и размера выборки.\n\n## Ограничения теста Стьюдента\n\n::: incremental\n-   Нормальность распределения - под вопросом.\n\n-   Независимость наблюдений - очень важно.\n\n-   Равенство дисперсий - необязательно для теста Велча.\n:::\n\n## Нужно ли нормальное распределение для t-теста?\n\nДавайте сначала оценим вероятность ошибки первого рода, когда мы многократно (10000 раз) извлекаем две выборки объемом 30 значений из стандартного нормального распределения и сравниваем их t-тестом:\n\nГенеральная совокупность одинаковая, следовательно мы ожидаем найти отличия не более чем в 5% случаев.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(replicate(10000, t.test(rnorm(30), rnorm(30))$p.value) < 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0499\n```\n:::\n:::\n\n\nВероятность получить ошибку первого рода (то есть найти отличия, там где их на самом деле нет) примерно 0.05.\n\nСсылки: [1](https://koch-kir.medium.com/%D0%B8%D1%81%D1%82%D0%BE%D1%80%D0%B8%D1%8F-%D0%BE%D0%B4%D0%BD%D0%BE%D0%B3%D0%BE-%D0%BE%D0%B1%D0%BC%D0%B0%D0%BD%D0%B0-%D0%B8%D0%BB%D0%B8-%D1%82%D1%80%D0%B5%D0%B1%D0%BE%D0%B2%D0%B0%D0%BD%D0%B8%D1%8F-%D0%BA-%D1%80%D0%B0%D1%81%D0%BF%D1%80%D0%B5%D0%B4%D0%B5%D0%BB%D0%B5%D0%BD%D0%B8%D1%8E-%D0%B2-%D1%81%D1%82%D0%B0%D1%82%D0%B8%D1%81%D1%82%D0%B8%D1%87%D0%B5%D1%81%D0%BA%D0%B8%D1%85-%D1%82%D0%B5%D1%81%D1%82%D0%B0%D1%85-55139a5558d), [2](https://pozdniakov.github.io/tidy_stats/320-ttest.html#sec-assumptions_ttest).\n\n## Теперь такую же процедуру для логнормального распределения\n\nГенеральная совокупность одинаковая, следовательно мы ожидаем найти отличия не более чем в 5% случаев.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmean(replicate(10000, t.test(rlnorm(30), rlnorm(30))$p.value) < 0.05)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 0.0376\n```\n:::\n:::\n\n\nВероятность ошибки первого рода даже меньше!\n\nЧто насчет графического способа определения p-value?\n\n## Попробуем отрисовать qqplot для нормального распределения\n\nqqplot - quantile-quantile plot.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(car)\nset.seed(50)\nsamp <- rnorm(30)\nqqPlot(samp)\n```\n\n::: {.cell-output-display}\n![](statR_lecture8_files/figure-revealjs/unnamed-chunk-7-1.png){width=3000}\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 26 24\n```\n:::\n:::\n\n\nВ нормальном распределении точки должны располагаться на синей линии.\n\n## Попробуем отрисовать гистограмму\n\n\n::: {.cell}\n\n```{.r .cell-code}\nhist(samp)\n```\n\n::: {.cell-output-display}\n![](statR_lecture8_files/figure-revealjs/unnamed-chunk-8-1.png){width=3000}\n:::\n:::\n\n\nВывод: не всегда графический способ позволяет определить принадлежность данных нормальному распределению, поскольку при малых объемах выборки даже настоящее нормальное распределение может не выглядеть как нормальное.\n\n## Тест Шапиро-Уилка (Shapiro-Wilk) для проверки на нормальность\n\n\n::: {.cell}\n\n```{.r .cell-code}\nshapiro.test(samp)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  samp\nW = 0.94952, p-value = 0.1641\n```\n:::\n:::\n\n\nВ нашем случае p-value больше 0.05, что логично: мы взяли эту выборку именно из нормального распределения. Если p-value меньше уровня $\\alpha$, который у нас стандартно 0.05, то мы можем отвергнуть нулевую гипотезу о том, что выборка взята из нормального распределения.\n\n::: callout-warning\nОднако тест Шапиро-Уилка это такой же статистический тест, как и другие, следовательно, чем больше выборка, тем с большей вероятностью он найдет отклонения от нормальности.\n:::\n\n## Непараметрические тесты\n\nТем не менее, бывают ситуации, когда тест Стьюдента неприменим, например в случае явных выбросов. В таком случае можно использовать непараметрический аналог - тест Манна-Уитни.\n\nКроме того, непараметрические методы подходят для интервальных и ранговых шкал, где арифметическое среднее не имеет физического смысла.\n\nНепараметрические тесты не опираются на *параметры* заранее известных распределений (например нормального), следовательно, более устойчивы к нарушению предположений параметрических тестов.\n\n## Тест Манна-Уитни (Mann-Whitney): теория {style=\"font-size: 90%\"}\n\nH~0~: $P(A > B) = 0.5$ вероятность того, что случайное число из распределения *A* больше, чем случайное число из распределения *B* равно 50%.\n\nH~1~: $P(A > B) \\neq 0.5$ вероятность, что случайное число из *A* больше чем *B* не равно 50%, следовательно распределения *A* и *B* отличаются сдвигом местоположения.\n\nИллюстрация:\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](statR_lecture8_files/figure-revealjs/unnamed-chunk-10-1.png){width=3000}\n:::\n:::\n\n\n## Тест Манна-Уитни (Mann-Whitney): формула {style=\"font-size: 90%\"}\n\nЧисла из обеих выборок ранжируются, то есть расставляются по порядку и самому наименьшему числу присваивается ранг 1, следующему 2, и так далее. Затем вычисляется тестовая U-статистика.\n\nДля независимых выборок - функция `wilcox.test()`, синтаксис такой же как и для `t.test()`:\n\n\n::: {.cell}\n\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(wc3_units_armor$hp ~ wc3_units_armor$armor_type)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning in wilcox.test.default(x = DATA[[1L]], y = DATA[[2L]], ...): не могу\nподсчитать точное p-значение при наличии повторяющихся наблюдений\n```\n:::\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon rank sum test with continuity correction\n\ndata:  wc3_units_armor$hp by wc3_units_armor$armor_type\nW = 78.5, p-value = 0.01472\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n:::\n\n\nВ случае повторяющихся значений есть несколько стратегий вычисления рангов, в нашем случае присваются дробные ранги.\n\n## Визуализация данных и проверка на нормальность распределения\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwc3_units_armor %>% \n  ggplot(aes(armor_type, hp))+\n  geom_boxplot(width = 0.2)\n```\n\n::: {.cell-output-display}\n![](statR_lecture8_files/figure-revealjs/unnamed-chunk-13-1.png){width=1800}\n:::\n:::\n\n::: {.cell output-location='column'}\n\n```{.r .cell-code}\nwc3_units_armor %>% \n  filter(armor_type == 'Heavy') %>% \n  pull(hp) %>% \n  shapiro.test()\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tShapiro-Wilk normality test\n\ndata:  .\nW = 0.87888, p-value = 0.003173\n```\n:::\n:::\n\n\n## Тест Вилкоксона (Wilcoxon) для зависимых выборок\n\nНепараметрический аналог теста Стьюдента для зависимых выборок.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nwilcox.test(diet1$pre.weight, diet1$weight6weeks, paired = TRUE)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n\tWilcoxon signed rank test with continuity correction\n\ndata:  diet1$pre.weight and diet1$weight6weeks\nV = 299, p-value = 2.203e-05\nalternative hypothesis: true location shift is not equal to 0\n```\n:::\n:::\n\n\nУ непараметрических тестов меньше мощность из-за редуцирования информации при переводе в ранги.\n\n\n::: {.cell}\n\n```{.r .cell-code}\n# вспомним результат t-теста\nt.test(diet1$pre.weight, diet1$weight6weeks, paired = TRUE)$p.value\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] 2.396734e-07\n```\n:::\n:::\n\n\n## Дисперсионный анализ (ANOVA)\n\nДисперсионный анализ (analysis of variance, ANOVA) --- метод для сравнения средних в трех и более группах.\n\nВиды дисперсионного анализа:\n\n-   Однофакторный (one-way)\n\n-   Двухфакторный (two-way)\n\n-   MANOVA (Multivariate analysis of variance)\n\n-   ANCOVA\n\nМы будем подробно рассматривать первые два.\n\n# Однофакторный дисперсионный анализ {#one_way_anova}\n\n## Однофакторный дисперсионный анализ: данные {style=\"font-size: 90%\"}\n\nДопустим, мы хотим сравнить средюю потерю веса для различных диет.\n\nТерминология: потеря веса является *зависимой переменной*, тип диеты - *независимая переменная*. Зависимая переменная - непрерывная, независимая - категориальная.\n\n**1 этап: формулировка нулевой и альтернативной гипотезы.**\n\nH~0~: все средние равны. $\\mu_1 = \\mu_2 = \\mu_3$\n\nH~1~: хотя бы одно среднее не равно остальным.\n\nДля начала проверим, сколько наблюдений для каждой из диет:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiet %>% \n  count(Diet)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 2\n   Diet     n\n  <dbl> <int>\n1     1    24\n2     2    27\n3     3    27\n```\n:::\n:::\n\n\n3 группы. Данные сбалансированы (то есть примерно одинаковое количество наблюдений для каждой группы), это важно для дисперсионного анализа.\n\n## Однофакторный дисперсионный анализ: подготовка данных\n\n\n::: {.cell}\n\n```{.r .cell-code}\nslice_sample(diet, n = 5)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 5 × 7\n  Person gender   Age Height pre.weight  Diet weight6weeks\n   <dbl>  <dbl> <dbl>  <dbl>      <dbl> <dbl>        <dbl>\n1     48      1    40    171         79     2         72.9\n2     56      0    36    160         66     3         58.2\n3     31      0    20    169         62     2         55  \n4     45      1    45    160         78     2         72.7\n5     77      1    40    167         87     3         77.8\n```\n:::\n:::\n\n\nНам нужно создать переменную, отражающую потерю веса, перекодировать тип диеты в фактор и удалить пропущенные значения.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiet <- diet %>%\n  mutate(weight_loss = weight6weeks - pre.weight,\n         Dietf = factor(Diet, labels = LETTERS[1:3]),\n         Person = factor(Person)) %>%\n  drop_na()\n```\n:::\n\n\n## Визуализация данных\n\nПопробуем отрисовать боксплот:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndiet %>% \n  ggplot(aes(Dietf, weight_loss, fill = Dietf))+\n  geom_boxplot()\n```\n\n::: {.cell-output-display}\n![](statR_lecture8_files/figure-revealjs/unnamed-chunk-20-1.png){width=3000}\n:::\n:::\n\n\nПохоже, что диета C отличается от остальных. Давайте теперь проверим статистически!\n\n## Однофакторный дисперсионный анализ: код\n\nИспользуем встроенную в base R функцию `aov()` (analysis of variance).\n\n\n::: {.cell}\n\n```{.r .cell-code}\naov(weight_loss ~ Dietf, data = diet)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nCall:\n   aov(formula = weight_loss ~ Dietf, data = diet)\n\nTerms:\n                   Dietf Residuals\nSum of Squares   60.5270  410.4018\nDeg. of Freedom        2        73\n\nResidual standard error: 2.371064\nEstimated effects may be unbalanced\n```\n:::\n:::\n\n\n## Однофакторный дисперсионный анализ: формула\n\n|                 | Степени свободы  | Суммы квадратов           | Средние квадраты                | F-статистика              |\n|-----------------|------------------|---------------------------|---------------------------------|---------------------------|\n| Межгрупповые    | $df_{b} = J - 1$ | $SS_{b}$                  | $MS_{b} =\\frac{SS_{b}}{df_{b}}$ | $F=\\frac{MS_{b}}{MS_{w}}$ |\n| Внутригрупповые | $df_{w} = N - J$ | $SS_{w}$                  | $MS_{w} =\\frac{SS_{w}}{df_{w}}$ |                           |\n| Общие           | $df_{t} = N - 1$ | $SS_{t}= SS_{b} + SS_{w}$ |                                 |                           |\n\n$J$ означает количество групп, $N$ - общее количество наблюдений во всех группах.\n\n## Однофакторный дисперсионный анализ: формула\n\n|                 | Степени свободы  | Суммы квадратов                                                                       | Средние квадраты                | F-статистика              |\n|-----------------|------------------|---------------------------------------------------------------------------------------|---------------------------------|---------------------------|\n| Межгрупповые    | $df_{b} = J - 1$ | $SS_{b}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (\\overline{x_j}-\\overline{x})^2$ | $MS_{b} =\\frac{SS_{b}}{df_{b}}$ | $F=\\frac{MS_{b}}{MS_{w}}$ |\n| Внутригрупповые | $df_{w} = N - J$ | $SS_{w}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (x_{ij}-\\overline{x_j})^2$       | $MS_{w} =\\frac{SS_{w}}{df_{w}}$ |                           |\n| Общие           | $df_{t} = N - 1$ | $SS_{t}= \\sum\\limits_{j=1}^J \\sum\\limits_{i=1}^{n_j} (x_{ij}-\\overline{x})^2$         |                                 |                           |\n\n$n_j$ означает количество наблюдений в группе $j$, а $x_{ij}$ - наблюдение под номером $i$ в группе $j$.\n\n## Однофакторный дисперсионный анализ: формула\n\nВариабельность обозначается $SS$ и означает \"сумму квадратов\" (sum of squares) - почти тоже самое, что и дисперсия, только мы не делим в конце на количество наблюдений:\n\n$$\nSS = \\sum\\limits_{i=1}^{n_j} (x_{i}-\\overline{x})^2\n$$\n\nПопробуем рассчитать самостоятельно по формулам, используя R.\n\n## Однофакторный дисперсионный анализ: код\n\nСохраним результат вызова `aov()` в переменную `fit_diet`, чтобы вызвать `summary()`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit_diet <- aov(weight_loss ~ Dietf, data = diet)\nsummary(fit_diet)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n            Df Sum Sq Mean Sq F value Pr(>F)   \nDietf        2   60.5  30.264   5.383 0.0066 **\nResiduals   73  410.4   5.622                  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n:::\n\n\np-value \\< 0.05, следовательно, мы отклоняем нулевую гипотезу. Какие диеты отличаются между собой?\n\n## Постхок-тесты для дисперсионного анализа {style=\"font-size: 90%\"}\n\nРекомендую использовать поправку Тьюки для определения, какие именно группы различаются.\n\nПоправка Тьюки похожа на тест Стьюдента, однако различается формула расчета стандартного отклонения в знаменателе, поэтому учитывается вклад всех групп.\n\nФункция `TukeyHSD()` принимает на вход объект класса `aov`.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nTukeyHSD(fit_diet)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n  Tukey multiple comparisons of means\n    95% family-wise confidence level\n\nFit: aov(formula = weight_loss ~ Dietf, data = diet)\n\n$Dietf\n         diff       lwr        upr     p adj\nB-A  0.032000 -1.589085  1.6530850 0.9987711\nC-A -1.848148 -3.439554 -0.2567422 0.0188047\nC-B -1.880148 -3.454614 -0.3056826 0.0152020\n```\n:::\n:::\n\n\nИтак, мы видим, что диета C отличается от A и от B, диеты A и B между собой не различаются.\n\nВ литературе по статистике можно встретить \"правило\", якобы нельзя использовать поправку Тьюки перед выполнением ановы, но на самом деле это не так, если задача узнать, какие групры различаются, то можно использовать сразу Тьюки.\n\n## Спасибо за внимание!\n\nЕсли понравилось, переходите по [ссылке](https://www.tinkoff.ru/rm/ubogoeva.elena1/TSRBI31474):\n\n![](images/qrcode.png)\n",
    "supporting": [
      "statR_lecture8_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-after-body": [
        "\r\n<script>\r\n  // htmlwidgets need to know to resize themselves when slides are shown/hidden.\r\n  // Fire the \"slideenter\" event (handled by htmlwidgets.js) when the current\r\n  // slide changes (different for each slide format).\r\n  (function () {\r\n    // dispatch for htmlwidgets\r\n    function fireSlideEnter() {\r\n      const event = window.document.createEvent(\"Event\");\r\n      event.initEvent(\"slideenter\", true, true);\r\n      window.document.dispatchEvent(event);\r\n    }\r\n\r\n    function fireSlideChanged(previousSlide, currentSlide) {\r\n      fireSlideEnter();\r\n\r\n      // dispatch for shiny\r\n      if (window.jQuery) {\r\n        if (previousSlide) {\r\n          window.jQuery(previousSlide).trigger(\"hidden\");\r\n        }\r\n        if (currentSlide) {\r\n          window.jQuery(currentSlide).trigger(\"shown\");\r\n        }\r\n      }\r\n    }\r\n\r\n    // hookup for slidy\r\n    if (window.w3c_slidy) {\r\n      window.w3c_slidy.add_observer(function (slide_num) {\r\n        // slide_num starts at position 1\r\n        fireSlideChanged(null, w3c_slidy.slides[slide_num - 1]);\r\n      });\r\n    }\r\n\r\n  })();\r\n</script>\r\n\r\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}